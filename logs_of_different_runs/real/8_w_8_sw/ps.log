This is a parameter server!
.
Sent 1 packets.
wating for a signal...
reading files...
files to read from:
./logs/root_switch/dict.txt
name conv1.weight

name conv1.bias

name conv2.weight

name conv2.bias

name fc1.weight

name fc1.bias

name fc2.weight


aggregating received dicts...
writing file...
signaling switches...
.
Sent 1 packets.
/usr/src/app/./distri_ml_ys.py:45: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  return F.log_softmax(x)
/usr/local/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.
  warnings.warn(warning.format(ret))

Test set: Avg. loss: 1.8061, Accuracy: 6504/10000 (65%)

Finished Epoch Number 1
Average time to compute new model: 0.002202749252319336s
Average time it takes the server to read all the new files: 0.02649688720703125
Avergae time to test: 9.648331880569458s


accuracies: [65.04000091552734]


test losses: [1.80609189453125]
wating for a signal...
reading files...
files to read from:
./logs/root_switch/dict.txt
name conv1.weight

name conv1.bias

name conv2.weight

name conv2.bias

name fc1.weight

name fc1.bias

name fc2.weight


aggregating received dicts...
writing file...
signaling switches...
.
Sent 1 packets.

Test set: Avg. loss: 0.6100, Accuracy: 8475/10000 (85%)

Finished Epoch Number 2
Average time to compute new model: 0.002197265625s
Average time it takes the server to read all the new files: 0.027170658111572266
Avergae time to test: 9.497226357460022s


accuracies: [65.04000091552734, 84.75]


test losses: [1.80609189453125, 0.6100225646972657]
wating for a signal...
reading files...
files to read from:
./logs/root_switch/dict.txt
name conv1.weight

name conv1.bias

name conv2.weight

name conv2.bias

name fc1.weight

name fc1.bias

name fc2.weight


aggregating received dicts...
writing file...
signaling switches...
.
Sent 1 packets.

Test set: Avg. loss: 0.4055, Accuracy: 8987/10000 (90%)

Finished Epoch Number 3
Average time to compute new model: 0.001897732416788737s
Average time it takes the server to read all the new files: 0.026030937830607098
Avergae time to test: 9.56526788075765s


accuracies: [65.04000091552734, 84.75, 89.87000274658203]


test losses: [1.80609189453125, 0.6100225646972657, 0.40548482055664065]
wating for a signal...
reading files...
files to read from:
./logs/root_switch/dict.txt
name conv1.weight

name conv1.bias

name conv2.weight

name conv2.bias

name fc1.weight

name fc1.bias

name fc2.weight


aggregating received dicts...
writing file...
signaling switches...
.
Sent 1 packets.

Test set: Avg. loss: 0.3166, Accuracy: 9167/10000 (92%)

Finished Epoch Number 4
Average time to compute new model: 0.0017238855361938477s
Average time it takes the server to read all the new files: 0.02507227659225464
Avergae time to test: 9.652017831802368s


accuracies: [65.04000091552734, 84.75, 89.87000274658203, 91.66999816894531]


test losses: [1.80609189453125, 0.6100225646972657, 0.40548482055664065, 0.3166150268554688]
wating for a signal...
reading files...
files to read from:
./logs/root_switch/dict.txt
name conv1.weight

name conv1.bias

name conv2.weight

name conv2.bias

name fc1.weight

name fc1.bias

name fc2.weight


aggregating received dicts...
writing file...
signaling switches...
.
Sent 1 packets.

Test set: Avg. loss: 0.2591, Accuracy: 9276/10000 (93%)

Finished Epoch Number 5
Average time to compute new model: 0.0016570091247558594s
Average time it takes the server to read all the new files: 0.02413973808288574
Avergae time to test: 8.747236824035644s


accuracies: [65.04000091552734, 84.75, 89.87000274658203, 91.66999816894531, 92.76000213623047]


test losses: [1.80609189453125, 0.6100225646972657, 0.40548482055664065, 0.3166150268554688, 0.2591310348510742]
Simulation is done!
